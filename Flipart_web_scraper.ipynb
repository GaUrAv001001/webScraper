{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "Customer_name = []\n",
    "places = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "discription = []\n",
    "rt_class = [\"_3LWZlK _1BLPMq\",\"_3LWZlK _1rdVr6 _1BLPMq\",\"_3LWZlK _32lA32 _1BLPMq\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Customer Name                 Reviews  \\\n",
      "0       Ricky Customer               Excellent   \n",
      "1       Khushiram Yogi                Terrific   \n",
      "2         Sohel  Asgar              Delightful   \n",
      "3   Mohd Shafik Ansari       Terrific purchase   \n",
      "4      Satish Jaiswal                Fabulous!   \n",
      "..                 ...                     ...   \n",
      "95   Flipkart Customer                    Good   \n",
      "96   Krishna Prajapati  Don't waste your money   \n",
      "97      Tirtharaj Sahu          Unsatisfactory   \n",
      "98       Chayan  Lodhi               Must buy!   \n",
      "99    MITHLESH  KUMAR          Waste of money!   \n",
      "\n",
      "                                         Place Ratings  \n",
      "0                   Certified Buyer, New Delhi       5  \n",
      "1                  Certified Buyer, Mehandipur       5  \n",
      "2              Certified Buyer, Haora District       4  \n",
      "3      Certified Buyer, Kundli Industrial Area       5  \n",
      "4                 Certified Buyer, Vasai Virar       5  \n",
      "..                                         ...     ...  \n",
      "95                  Certified Buyer, Hyderabad       3  \n",
      "96  Certified Buyer, Phulpur Azamgarh District       1  \n",
      "97        Certified Buyer, Subarnapur District       1  \n",
      "98                  Certified Buyer, Irongmara       5  \n",
      "99                    Certified Buyer, Bettiah       1  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    url = \"https://www.flipkart.com/infinix-smart-7-azure-blue-64-gb/product-reviews/itm7b72b66485a59?pid=MOBGMTW2WYG2A2FM&lid=LSTMOBGMTW2WYG2A2FMAZGXKU&marketplace=FLIPKART&page=\"+str(i)\n",
    "    r = requests.get(url)\n",
    "    # print(r)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    box = soup.find(\"div\", class_=\"_1YokD2 _3Mn1Gg col-9-12\")\n",
    "\n",
    "    # Customer Name\n",
    "    names = box.find_all(\"p\", class_ = \"_2sc7ZR _2V5EHH\")\n",
    "    for i in names:\n",
    "        name = i.text\n",
    "        Customer_name.append(name)\n",
    "\n",
    "    # Customer Review\n",
    "    rev = box.find_all(\"p\", class_=\"_2-N8zT\")\n",
    "    for i in rev:\n",
    "        review = i.text\n",
    "        reviews.append(review)\n",
    "\n",
    "    # Customer Place\n",
    "    plc = box.find_all(\"p\", class_=\"_2mcZGG\")\n",
    "    for i in plc:\n",
    "        place = i.text\n",
    "        places.append(place)\n",
    "    # print(len(places))\n",
    "\n",
    "\n",
    "    rt = box.find_all(\"div\", class_ = rt_class)\n",
    "    for i in rt:\n",
    "        rating = i.text\n",
    "        ratings.append(rating)\n",
    "    # print(\"rating: \",len(ratings))\n",
    "\n",
    "\n",
    "    #     disc = box.find_all(\"div\", class_=\"t-ZTKy\" )\n",
    "    #     for i in disc:\n",
    "    #         Desc = i.text\n",
    "    #         # print(len(Desc))\n",
    "    #         discription.append(Desc)\n",
    "    #     print(len(discription))\n",
    "    # except requests.exceptions.RequestException as e:\n",
    "    #     print(\"Error:\", e)\n",
    "    #     continue\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Customer Name\":Customer_name,\"Reviews\":reviews,\"Place\":places,\"Ratings\":ratings})\n",
    "print(df)\n",
    "\n",
    "    # print(soup)\n",
    "\n",
    "    # nextPage = soup.find(\"a\", class_ = \"ge-49M\").get(\"href\")\n",
    "    # cnp = \"https://www.flipkart.com\"+nextPage\n",
    "    # print(cnp)\n",
    "\n",
    "# url = cnp\n",
    "# r = requests.get(url)\n",
    "# soup = BeautifulSoup(r.text,\"lxml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
